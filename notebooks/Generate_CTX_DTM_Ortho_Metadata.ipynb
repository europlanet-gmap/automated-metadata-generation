{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "graphic-lightweight",
   "metadata": {},
   "source": [
    "# Generate CTX DTM & Ortho Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-provider",
   "metadata": {},
   "source": [
    "First we have the necessart imports. These are largely encapsulated inside of the automated metadata generation (`amg`) library. THe only external things we import are `json` (so that we can write out STAC files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "clinical-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "from amg.isismetadata import IsisMetadata\n",
    "from amg.fgdcmetadata import FGDCMetadata, OrthographicFgdcParser\n",
    "from amg.gdalmetadata import GDALMetadata\n",
    "from amg.databasemetadata import DbMetadata\n",
    "from amg.plaintextmetadata import PcAlignMetadata\n",
    "from amg.formatters.stac_formatter import to_stac\n",
    "from amg.formatters.fgdc_formatter import to_fgdc\n",
    "from amg.utils import find_file, write_fgdc, write_stac\n",
    "from amg import UnifiedMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-framing",
   "metadata": {},
   "source": [
    "## Step I: Stage the data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "exempt-belief",
   "metadata": {
    "tags": []
   },
   "source": [
    "import fileinput\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "DESTINATION_DIR = '/scratch/ARD/stac/mars'\n",
    "BASEDIR = '/scratch/ARD/processed/ctx_dtms/mc15_elysium/'\n",
    "\n",
    "def copy_file(source, destination):\n",
    "    #if not os.path.exists(os.path.join(destination, os.path.basename(source))):\n",
    "    shutil.copy2(source, destination)\n",
    "    assert os.path.exists(destination)\n",
    "\n",
    "def stage_stereo_ortho(datadir, dtm_subpath='ctx_dtms', ortho_subpath='ctx_dtm_orthos'):\n",
    "    # Find the data\n",
    "    dem = find_file(datadir, 'results_ba', '*DEM-adj-cog.tif')\n",
    "    dem_thumbnail = find_file(datadir, 'results_ba', '*DEM-adj-cog.jpg')\n",
    "    intersection_err = find_file(datadir, 'results_ba', '*IntersectionErr*')\n",
    "    ortho = find_file(datadir, 'results_ba', '*DRG-cog.tif')\n",
    "    ortho_thumbnail = find_file(datadir, 'results_ba', '*DRG-cog.jpg')\n",
    "    hillshade = find_file(datadir, 'results_ba', '*hs-cog.tif')\n",
    "    hillshade_thumbnail = find_file(datadir, 'results_ba', '*hs-cog.jpg')\n",
    "    qa_metrics = find_file(datadir, 'results_ba', 'qa_metrics.txt')\n",
    "    asp_provenance = find_file(datadir, 'results_ba', 'asp_provenance.txt')\n",
    "    isis_provenance = find_file(datadir, 'isis_provenance.txt')\n",
    "\n",
    "    if None in [dem, ortho]:\n",
    "        \n",
    "        # Processing failed\n",
    "        return\n",
    "    \n",
    "    # Generate the output directory for the data to be staged\n",
    "    pairname = os.path.basename(datadir)\n",
    "    dtm_destination_dir = os.path.join(DESTINATION_DIR, dtm_subpath, pairname)\n",
    "    if not os.path.exists(dtm_destination_dir):\n",
    "        os.mkdir(dtm_destination_dir)\n",
    "       \n",
    "    # Move the DTM data\n",
    "    data_to_move = []\n",
    "    for data in [dem, dem_thumbnail, \n",
    "                 qa_metrics, \n",
    "                 ortho, ortho_thumbnail, \n",
    "                 hillshade, hillshade_thumbnail]:\n",
    "        if '-adj-hs' in data:\n",
    "            outname = os.path.basename(data).replace('_ba-aligned-DEM-adj-hs-cog', '_HILLSHADE')\n",
    "        elif 'DEM' in data:\n",
    "            outname = os.path.basename(data).replace('_ba-aligned-DEM-adj-cog', '_DEM')\n",
    "        elif 'DRG' in data:\n",
    "            outname = os.path.basename(data).replace('_ba-aligned-DRG-cog', '_ORTHO')\n",
    "        elif 'Intersection' in data:\n",
    "            outname = os.path.basename(data).replace('_ba-aligned-', '_')\n",
    "        else:\n",
    "            outname = os.path.basename(data)\n",
    "        data_renamed = os.path.join(dtm_destination_dir, outname)\n",
    "        data_to_move.append((data, data_renamed))\n",
    "    \n",
    "    for source, destination in data_to_move:\n",
    "        copy_file(source, destination)\n",
    "    \n",
    "    destination = os.path.join(dtm_destination_dir, outname)\n",
    "    with fileinput.input(files=(isis_provenance, asp_provenance)) as f:\n",
    "        with open(os.path.join(dtm_destination_dir, 'provenance.txt'), 'w') as p:\n",
    "            for line in f:\n",
    "                p.write(line)\n",
    "\n",
    "\n",
    "\n",
    "for datadir in glob.glob(BASEDIR + '*'):\n",
    "    #try:\n",
    "    stage_stereo_ortho(datadir)\n",
    "    #except:\n",
    "    #    print(datadir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-secondary",
   "metadata": {},
   "source": [
    "⭐️⭐️⭐️ If the STAC collection / catalog do not already exist, they need to be created **before** pushing stac messages to SQS. The [ARD repository](https://github.com/USGS-Astrogeology/ARD_STAC) has the full hierarchal organization of the STAC catalogs and collections. ⭐️⭐️⭐️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-kuwait",
   "metadata": {},
   "source": [
    "### Step II: Generate the STAC and FGDC metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "editorial-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /scratch/ARD/stac/mars/ctx_dtms/2021_6_30.lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "following-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGED_DTMS = '/scratch/ARD/stac/mars/ctx_dtms/'\n",
    "OUTFILE = '2021_6_30.lis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ranking-swaziland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "stac_files = []\n",
    "def create_unified_ctx_metadata_obj(basename, dtm, ortho, qa_metrics):\n",
    "    image_a = basename.split('__')[0]\n",
    "    image_b = basename.split('__')[1]\n",
    "    sql = f\"\"\"\n",
    "    WITH cte_geoms AS\n",
    "        (\n",
    "        SELECT id, geom FROM ctx\n",
    "        WHERE \n",
    "            ctx.name = ANY(array ['{image_a}', '{image_b}'])\n",
    "        )\n",
    "    SELECT ST_AsText(ST_Extent(ST_Intersection(A.geom, B.geom))) FROM cte_geoms as A, cte_geoms as B\n",
    "    WHERE A.id > B.id AND A.id != B.id\n",
    "    \"\"\"\n",
    "    db = DbMetadata('mars', 'postgresql://jay:abcde@autocnet.wr.usgs.gov:30001', sql=sql)\n",
    "\n",
    "    # Define mappings\n",
    "    mappings = {'bbox':DbMetadata, 'footprint':DbMetadata, }\n",
    "    \n",
    "    # Define overrides\n",
    "    dtm_overrides = {'license': 'PDDL-1.0',\n",
    "                 'productid': f'{basename}_DEM', \n",
    "                 'basename': f'{basename}',\n",
    "                 'missions':['Mars Reconnaissance Orbiter'],\n",
    "                 'instruments':['Context Camera (CTX)'],\n",
    "                 'doi':'https://doi.org/10.5066/P9JKVWR3',\n",
    "                 'href':f'https://asc-mars.s3-us-west-2.amazonaws.com/ctx_dtms/{basename}',\n",
    "                 'longitude_domain':360,\n",
    "                 'horizontal_accuracy_value':'50',\n",
    "                 'horizontal_accuracy_report':'A priori CTX pointing is generally within plus or minus 50m of the MOLA datum.',\n",
    "                 'horizontal_accuracy_test_name':'Best estimate',\n",
    "                 'vertical_accuracy_report': 'Vertical accuracy is assessed by comparing the offsets between the generated DTM and the Ultimate MOLA point cloud.',\n",
    "                 'epsg':49900,\n",
    "                 'title':f'Ames Stereo Pipeline Derived 20mpp Content Camera DTM and Ortho Image; Mars; {image_a}, {image_b}',\n",
    "                 'processing_environment':'Data generated using ISIS4.3.0, GDAL 3.1.4, Ames Stereo Pipeline 2.7.0'}\n",
    "    \n",
    "    fgdc = FGDCMetadata('../templates/mroctx_dtm_template.xml', proj='orthogr')\n",
    "    gd = GDALMetadata(dtm)\n",
    "    vrt = PcAlignMetadata(qa)\n",
    "    # Create a unified metadata object\n",
    "    dtm_record = UnifiedMetadata([fgdc, gd, db, vrt], overrides=dtm_overrides, mappings=mappings)\n",
    "    \n",
    "    return dtm_record\n",
    "        \n",
    "for i, basedir in enumerate(glob.glob(STAGED_DTMS + '/*')):\n",
    "    # This is all file manipulation to make sure data are staged properly\n",
    "    if 'collection.json' in basedir:\n",
    "        continue\n",
    "    dtm = find_file(basedir,  '*DEM.tif')\n",
    "    ortho = find_file(basedir, '*ORTHO.tif')\n",
    "    qa = find_file(basedir, 'qa_metrics.txt')\n",
    "    \n",
    "    # This builds the metadata record\n",
    "    dtm_record = create_unified_ctx_metadata_obj(os.path.basename(basedir), dtm, ortho, qa)\n",
    "    \n",
    "    # Generate and write FGDC\n",
    "    dtm_name = os.path.splitext(dtm)[0] \n",
    "    ort_name = os.path.splitext(ortho)[0]\n",
    "    write_fgdc(os.path.join(basedir, dtm_name + '.xml'), to_fgdc(dtm_record))\n",
    "    \n",
    "    # Manually define the assets for this set of products\n",
    "    dtm_assets = [{'title':'DEM Thumbnail',\n",
    "           'href':'{href}/{productid}.jpg',\n",
    "           'type':'image/jpeg',\n",
    "           'roles':['thumbnail'],\n",
    "           'key':'thumbnail'},\n",
    "          {'title': 'DEM',\n",
    "           'href':'{href}/{productid}.tif',\n",
    "           'type':'image/tiff; application=geotiff; profile=cloud-optimized',\n",
    "           'roles':['data'],\n",
    "           'key':'dem'},\n",
    "          {'title':'Hillshade',\n",
    "           'href':'{href}/{basename}_HILLSHADE.tif',\n",
    "           'type':'image/tiff; application=geotiff; profile=cloud-optimized',\n",
    "           'roles':['data'],\n",
    "           'key':'hillshade'},\n",
    "          {'title':'Orthoimage',\n",
    "           'href':'{href}/{basename}_ORTHO.tif',\n",
    "           'type':'image/tiff; application=geotiff; profile=cloud-optimized',\n",
    "           'roles':['data'],\n",
    "           'key':'ortho image'},\n",
    "          {'title': 'FGDC Metadata',\n",
    "           'href':'{href}/{productid}.xml',\n",
    "           'type':'application/xml',\n",
    "           'roles':['metadata'],\n",
    "           'key':'fgdc_metadata'},\n",
    "          {'title': 'Quality Assurance Metrics',\n",
    "           'href': '{href}/qa_metrics.txt',\n",
    "           'type':'text/plain',\n",
    "           'roles': ['metadata'],\n",
    "           'key':'qa_metric'},\n",
    "          {'title': 'ASP generated intersection error raster',\n",
    "           'href':'{href}/{basename}_IntersectionErr.tif',\n",
    "           'type':'image/tiff; application=geotiff',\n",
    "           'roles':['metadata', 'data-mask'],\n",
    "           'key':'intersection_err'},\n",
    "          {'title':'Processing steps in ISIS and ASP used to generate the data product',\n",
    "           'href':'{href}/provenance.txt',\n",
    "           'type':'text/plain',\n",
    "           'roles':['metadata'],\n",
    "           'key':'provenance'\n",
    "          }]\n",
    "    \n",
    "    # Generate STAC\n",
    "    stac_dtm = to_stac(dtm_record, assets=dtm_assets)\n",
    "    stac_file = os.path.join(basedir, dtm_name + '.json')\n",
    "    write_stac(stac_file, stac_dtm)\n",
    "\n",
    "    # Append the stac file path to the list of file paths\n",
    "    stac_files.append(stac_file)\n",
    "    \n",
    "# Write the list of created STAC files to the outfile\n",
    "with open(os.path.join(STAGED_DTMS, OUTFILE), 'w') as f:\n",
    "    for stac_file in stac_files:\n",
    "        f.write(stac_file + '\\n')\n",
    "print('Done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-wellington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amg",
   "language": "python",
   "name": "amg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
